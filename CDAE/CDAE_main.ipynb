{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/larry/Py3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from CDAE import AutoEncoder\n",
    "from tqdm import trange\n",
    "from utils import *\n",
    "from sklearn.cluster import KMeans, spectral_clustering\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def get_map(list_):\n",
    "    map_ = {}\n",
    "    for idx, ident in enumerate(list_):\n",
    "        map_[ident] = idx\n",
    "        \n",
    "    return map_\n",
    "\n",
    "def get_matrix(data):\n",
    "    matrix = np.zeros((total_usr, total_item), dtype=np.float32)\n",
    "    for line in data:\n",
    "        uid = user_map[line[0]]\n",
    "        iid = item_map[line[1]]\n",
    "        matrix[uid, iid] = 1\n",
    "    \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "userList = np.load('../data/netflix/netflix_userList.npy')\n",
    "itemList = np.load('../data/netflix/netflix_itemList.npy')\n",
    "\n",
    "total_usr = len(userList)\n",
    "total_item = len(itemList)\n",
    "\n",
    "user_map = get_map(userList)\n",
    "item_map = get_map(itemList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_rating_all = np.load('../data/netflix/train_rating_all.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pickle\n",
    "\n",
    "train_indices_all = None\n",
    "test_indices_all = None\n",
    "\n",
    "with open('../data/netflix/train_indices_all.pkl', 'rb') as train_indice_file:\n",
    "    train_indices_all = pickle.load(train_indice_file)\n",
    "    train_indice_file.close()\n",
    "    \n",
    "with open('../data/netflix/test_indices_all.pkl', 'rb') as test_indice_file:\n",
    "    test_indices_all = pickle.load(test_indice_file)\n",
    "    test_indice_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparsity of ratings is 5.16%\n",
      "num. of users: 276, num. of items: 989, num. of ratings: 14072\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/itri/rating_itri_pruned.csv')\n",
    "df['freq'] = df.groupby('uid')['uid'].transform('count')  # count frequncy by column's values\n",
    "df = df[df['freq'] > 5]  # remove row which corresponding frequence < 5\n",
    "df_array = df.as_matrix()\n",
    "\n",
    "userList = sorted(df['uid'].unique())\n",
    "itemList = sorted(df['iid'].unique())\n",
    "\n",
    "total_usr = len(df['uid'].unique())\n",
    "total_item = len(df['iid'].unique())\n",
    "\n",
    "user_map = get_map(userList)\n",
    "item_map = get_map(itemList)\n",
    "    \n",
    "\n",
    "sparsity = len(df)/(total_usr*total_item)\n",
    "print(\"sparsity of ratings is %.2f%%\" %(sparsity*100))\n",
    "print (\"num. of users: %d, num. of items: %d, num. of ratings: %d\" % (total_usr, total_item, len(df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_vectors = np.load('../data/itri/feature_vectors.npy')\n",
    "pca = PCA(n_components=2, svd_solver='full')\n",
    "pca_out = pca.fit_transform(user_vectors)\n",
    "colors = np.random.rand(len(pca_out[:, 0]))\n",
    "\n",
    "\n",
    "plt.scatter(pca_out[:, 0], pca_out[:, 1], c=colors, alpha=0.5)\n",
    "plt.savefig('figs/i_feature_vecPCA_scatter.jpg')\n",
    "plt.gcf().clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='full', copy_x=True, init='k-means++', max_iter=300,\n",
       "    n_clusters=10, n_init=10, n_jobs=1, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_vectors = np.load('../data/itri/feature_vectors.npy')\n",
    "pca = PCA(n_components=10, svd_solver='full')\n",
    "pca_out = pca.fit_transform(user_vectors)\n",
    "NUM_CLUSTER = 10\n",
    "kmeans = KMeans(n_clusters=NUM_CLUSTER, n_init=10, algorithm='full')\n",
    "\n",
    "\n",
    "kmeans.fit(pca_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{4: 23, 1: 145, 5: 19, 7: 8, 8: 15, 9: 4, 6: 14, 2: 15, 3: 16, 0: 17}\n"
     ]
    }
   ],
   "source": [
    "label_map = {}\n",
    "for i in kmeans.labels_:\n",
    "    if i not in label_map:\n",
    "        label_map[i] = 1\n",
    "    else:\n",
    "        label_map[i] += 1\n",
    "\n",
    "print (label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_index = {}\n",
    "for i in range(NUM_CLUSTER):\n",
    "    label_index[i] = []\n",
    "    \n",
    "label_list = list(kmeans.labels_)\n",
    "\n",
    "for idx, i in enumerate(label_list):\n",
    "    label_index[i].append(idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "rating = np.zeros((total_usr, total_item), dtype=np.int8)\n",
    "for line in df_array:\n",
    "    uid = user_map[line[0]]\n",
    "    iid = item_map[line[1]]\n",
    "    rating[uid, iid] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0.\n",
      "INFO:tensorflow:Restoring parameters from model/cdae_0.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:05<00:00, 37.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 1.\n",
      "INFO:tensorflow:Restoring parameters from model/cdae_0.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:30<00:00,  6.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 2.\n",
      "INFO:tensorflow:Restoring parameters from model/cdae_0.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:04<00:00, 43.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 3.\n",
      "INFO:tensorflow:Restoring parameters from model/cdae_0.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:03<00:00, 51.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 4.\n",
      "INFO:tensorflow:Restoring parameters from model/cdae_0.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:04<00:00, 40.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 5.\n",
      "INFO:tensorflow:Restoring parameters from model/cdae_0.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:04<00:00, 48.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 6.\n",
      "INFO:tensorflow:Restoring parameters from model/cdae_0.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:03<00:00, 51.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 7.\n",
      "INFO:tensorflow:Restoring parameters from model/cdae_0.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:02<00:00, 78.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 8.\n",
      "INFO:tensorflow:Restoring parameters from model/cdae_0.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:03<00:00, 54.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 9.\n",
      "INFO:tensorflow:Restoring parameters from model/cdae_0.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 209.34it/s]\n"
     ]
    }
   ],
   "source": [
    "test_aps_5 = []\n",
    "test_aps_10 = []\n",
    "test_rec_5 = []\n",
    "test_rec_10 = []\n",
    "\n",
    "for i in range(NUM_CLUSTER):\n",
    "    print (\"Cluster %d.\" % (i))\n",
    "    train_rating = np.take(train_rating_all, label_index[i], axis=0)\n",
    "    train_user = label_index[i]\n",
    "    # train_rating, train_indices, test_indices = gen_train_test(rating_n)\n",
    "    # train_rating = np.take(rating, label_index[i], axis=0)\n",
    "    train_indices = np.take(train_indices_all, label_index[i])\n",
    "    test_indices = np.take(test_indices_all, label_index[i])\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    autoencoder = AutoEncoder(user_num=total_usr, item_num=total_item, mode='user', loss_function='cross_entropy',\n",
    "                              batch_size=1, epochs=200)\n",
    "    autoencoder.model_load(0)\n",
    "    autoencoder.train(rating=train_rating,\n",
    "                      train_idents=train_user,\n",
    "                      train_indices=train_indices,\n",
    "                      test_indices=test_indices)\n",
    "    \n",
    "    \"\"\"autoencoder.train(rating=rating,\n",
    "                     train_idents=train_user)\"\"\"\n",
    "    \n",
    "    test_ap_5 = autoencoder.log['ap@5']\n",
    "    test_ap_10 = autoencoder.log['ap@10']\n",
    "    recs_5 = autoencoder.log['recall@5']\n",
    "    recs_10 = autoencoder.log['recall@10']\n",
    "    \n",
    "    # top_N_ap = sorted(test_ap,reverse=True)[:20]\n",
    "    # test_aps.append(np.mean(top_N_ap))\n",
    "    \n",
    "    test_aps_5.append(max(test_ap_5))\n",
    "    test_aps_10.append(max(test_ap_10))\n",
    "    test_rec_5.append(max(recs_5))\n",
    "    test_rec_10.append(max(recs_10))\n",
    "    \n",
    "    \"\"\"plt.plot(range(len(test_ap_10)), test_ap_10, color='green', label='Test AP')\n",
    "    # plt.plot(range(len(test_loss)), test_loss, color='red', label='Test loss')\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.title(\"Train 200 epoch\")\n",
    "    plt.xlabel('#Epoch')\n",
    "    plt.ylabel('AP_10')\n",
    "    plt.savefig('./figs/test_ap_cluster_%d.jpg' % (i))\n",
    "    plt.gcf().clear()\"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0, aps: 0.220196, num: 17, weighted ap: 3.743333\n",
      "Cluster 1, aps: 0.046546, num: 145, weighted ap: 6.749167\n",
      "Cluster 2, aps: 0.531778, num: 15, weighted ap: 7.976667\n",
      "Cluster 3, aps: 0.318333, num: 16, weighted ap: 5.093333\n",
      "Cluster 4, aps: 0.065797, num: 23, weighted ap: 1.513333\n",
      "Cluster 5, aps: 0.064561, num: 19, weighted ap: 1.226667\n",
      "Cluster 6, aps: 0.526667, num: 14, weighted ap: 7.373333\n",
      "Cluster 7, aps: 0.588333, num: 8, weighted ap: 4.706667\n",
      "Cluster 8, aps: 0.516889, num: 15, weighted ap: 7.753333\n",
      "Cluster 9, aps: 0.145833, num: 4, weighted ap: 0.583333\n",
      "Over all average ap: 0.169272\n"
     ]
    }
   ],
   "source": [
    "ap_5 = 0\n",
    "\n",
    "for i in range(NUM_CLUSTER):\n",
    "    num = label_map[i]\n",
    "    \n",
    "    ap_5 += test_aps_5[i] * num\n",
    "    print (\"Cluster %d, aps: %f, num: %d, weighted ap: %f\" % (i, test_aps_5[i], num, test_aps_5[i]*num))\n",
    "    \n",
    "ap_5 = ap_5 / (total_usr)\n",
    "\n",
    "print (\"Over all average ap: %f\" % (ap_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0, aps: 0.146338, num: 17, weighted ap: 2.487738\n",
      "Cluster 1, aps: 0.046962, num: 145, weighted ap: 6.809464\n",
      "Cluster 2, aps: 0.447008, num: 15, weighted ap: 6.705119\n",
      "Cluster 3, aps: 0.241429, num: 16, weighted ap: 3.862857\n",
      "Cluster 4, aps: 0.040496, num: 23, weighted ap: 0.931402\n",
      "Cluster 5, aps: 0.043789, num: 19, weighted ap: 0.831984\n",
      "Cluster 6, aps: 0.360910, num: 14, weighted ap: 5.052738\n",
      "Cluster 7, aps: 0.471101, num: 8, weighted ap: 3.768810\n",
      "Cluster 8, aps: 0.377058, num: 15, weighted ap: 5.655873\n",
      "Cluster 9, aps: 0.103472, num: 4, weighted ap: 0.413889\n",
      "Over all average ap: 0.132318\n"
     ]
    }
   ],
   "source": [
    "ap_10 = 0\n",
    "\n",
    "for i in range(NUM_CLUSTER):\n",
    "    num = label_map[i]\n",
    "    \n",
    "    ap_10 += test_aps_10[i] * num\n",
    "    print (\"Cluster %d, aps: %f, num: %d, weighted ap: %f\" % (i, test_aps_10[i], num, test_aps_10[i]*num))\n",
    "    \n",
    "ap_10 = ap_10 / (total_usr)\n",
    "\n",
    "print (\"Over all average ap: %f\" % (ap_10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0, aps: 0.305882, num: 17, weighted ap: 5.200000\n",
      "Cluster 1, aps: 0.080805, num: 145, weighted ap: 11.716667\n",
      "Cluster 2, aps: 0.613333, num: 15, weighted ap: 9.200000\n",
      "Cluster 3, aps: 0.412500, num: 16, weighted ap: 6.600000\n",
      "Cluster 4, aps: 0.121739, num: 23, weighted ap: 2.800000\n",
      "Cluster 5, aps: 0.126316, num: 19, weighted ap: 2.400000\n",
      "Cluster 6, aps: 0.600000, num: 14, weighted ap: 8.400000\n",
      "Cluster 7, aps: 0.675000, num: 8, weighted ap: 5.400000\n",
      "Cluster 8, aps: 0.586667, num: 15, weighted ap: 8.800000\n",
      "Cluster 9, aps: 0.200000, num: 4, weighted ap: 0.800000\n",
      "Over all average ap: 0.222162\n"
     ]
    }
   ],
   "source": [
    "recall_5 = 0\n",
    "\n",
    "for i in range(NUM_CLUSTER):\n",
    "    num = label_map[i]\n",
    "    \n",
    "    recall_5 += test_rec_5[i] * num\n",
    "    print (\"Cluster %d, aps: %f, num: %d, weighted ap: %f\" % (i, test_rec_5[i], num, test_rec_5[i]*num))\n",
    "    \n",
    "recall_5 = recall_5 / (total_usr)\n",
    "\n",
    "print (\"Over all average ap: %f\" % (recall_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0, aps: 0.270588, num: 17, weighted ap: 4.600000\n",
      "Cluster 1, aps: 0.105153, num: 145, weighted ap: 15.247222\n",
      "Cluster 2, aps: 0.546667, num: 15, weighted ap: 8.200000\n",
      "Cluster 3, aps: 0.368750, num: 16, weighted ap: 5.900000\n",
      "Cluster 4, aps: 0.095221, num: 23, weighted ap: 2.190079\n",
      "Cluster 5, aps: 0.141813, num: 19, weighted ap: 2.694444\n",
      "Cluster 6, aps: 0.457143, num: 14, weighted ap: 6.400000\n",
      "Cluster 7, aps: 0.600000, num: 8, weighted ap: 4.800000\n",
      "Cluster 8, aps: 0.480000, num: 15, weighted ap: 7.200000\n",
      "Cluster 9, aps: 0.175000, num: 4, weighted ap: 0.700000\n",
      "Over all average ap: 0.209898\n"
     ]
    }
   ],
   "source": [
    "recall_10 = 0\n",
    "\n",
    "for i in range(NUM_CLUSTER):\n",
    "    num = label_map[i]\n",
    "    \n",
    "    recall_10 += test_rec_10[i] * num\n",
    "    print (\"Cluster %d, aps: %f, num: %d, weighted ap: %f\" % (i, test_rec_10[i], num, test_rec_10[i]*num))\n",
    "    \n",
    "recall_10 = recall_10 / (total_usr)\n",
    "\n",
    "print (\"Over all average ap: %f\" % (recall_10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For netflix huge dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "user_train_rating = np.load('../data/netflix/rating_matrix_CDAE.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_rating_all, train_indices_all, test_indices_all = gen_train_test(user_train_rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pickle\n",
    "\n",
    "np.save('../data/netflix/train_rating_all.npy', train_rating_all)\n",
    "\n",
    "with open('../data/netflix/train_indices_all.pkl', 'wb') as train_indice_file:\n",
    "    pickle.dump(train_indices_all, train_indice_file)\n",
    "    \n",
    "with open('../data/netflix/test_indices_all.pkl', 'wb') as test_indice_file:\n",
    "    pickle.dump(test_indices_all, test_indice_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = df.as_matrix()\n",
    "\n",
    "user_train_rating = np.zeros((total_usr, total_item), dtype=np.int32)\n",
    "\n",
    "for line in train_data:\n",
    "    uid = user_map[line[0]]\n",
    "    iid = item_map[line[1]]\n",
    "    user_train_rating[uid, iid] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topN = np.count_nonzero(user_train_rating, axis=0).argsort()[::-1][:10]\n",
    "others = [k for k in range(total_item) if k not in topN]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "train_rating_all, train_indices_all, test_indices_all = gen_train_test(user_train_rating)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "train_user_all = np.nonzero(np.count_nonzero(train_rating_all, axis=1))[0]\n",
    "\n",
    "autoencoder = AutoEncoder(user_num=total_usr, item_num=total_item, mode='user', denoise_function='dropout', \n",
    "                          loss_function='cross_entropy', batch_size=1, epochs=500)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "specify_vector_original = autoencoder.sess.run(autoencoder.vector_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import sklearn.metrics as metrics\n",
    "\n",
    "vector = {'i': -1, 'j': -1}\n",
    "\n",
    "max_sim = 0\n",
    "min_sim = 1\n",
    "\n",
    "for i in range(train_rating_all.shape[0]):\n",
    "    for j in range(i+1, train_rating_all.shape[0]):\n",
    "        sim_i_j = metrics.pairwise.cosine_similarity(\n",
    "            [train_rating_all[i]], [train_rating_all[j]])\n",
    "        \n",
    "        if sim_i_j == 0:\n",
    "            min_sim = sim_i_j\n",
    "            spec_sim_i_j = metrics.pairwise.cosine_similarity(\n",
    "                [specify_vector_original[i]], [specify_vector_original[j]])\n",
    "            \n",
    "            if spec_sim_i_j > max_sim:\n",
    "                max_sim = spec_sim_i_j\n",
    "                vector['i'] = i\n",
    "                vector['j'] = j\n",
    "                print (i, j)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "not_sim_list = [(137, 251), (198, 718), (234, 387), (380, 826), (442, 677)]\n",
    "not_sim_spec_vector = np.take(specify_vector_original, not_sim_list, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "simlarity_org_list = [metrics.pairwise.cosine_similarity(\n",
    "    [x[0]], [x[1]])[0][0] for x in not_sim_spec_vector]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "autoencoder.train(rating=train_rating_all,\n",
    "                  train_idents=train_user_all,\n",
    "                  train_indices=train_indices_all,\n",
    "                  test_indices=test_indices_all,\n",
    "                  topN=None,\n",
    "                  weight=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "specify_vector_trained = autoencoder.sess.run(autoencoder.vector_matrix)\n",
    "\n",
    "not_sim_spec_vector_trained = np.take(specify_vector_trained, not_sim_list, axis=0)\n",
    "\n",
    "simlarity_trained_list = [metrics.pairwise.cosine_similarity(\n",
    "    [x[0]], [x[1]])[0][0] for x in not_sim_spec_vector_trained]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print (simlarity_trained_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "print (simlarity_org_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "not_sim_list_ = ['(137, 251)', '(198, 718)', '(234, 387)', '(380, 826)']\n",
    "\n",
    "x = np.array([0,1,2,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.xticks(x, not_sim_list_)\n",
    "\n",
    "plt.plot(x, simlarity_org_list[:-1], color='green', marker='o', label='similarity_orginal')\n",
    "plt.plot(x, simlarity_trained_list[:-1], color='red', marker='x', label='similarity_trained')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.title(\"Specify vector similarity changes.\")\n",
    "plt.xlabel('Not similar user pair')\n",
    "plt.ylabel('Cosine Similarity')\n",
    "plt.savefig('./figs/Spevector_sim_changes.jpg')\n",
    "plt.show()\n",
    "plt.gcf().clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [01:03<00:00,  3.14it/s]\n"
     ]
    }
   ],
   "source": [
    "train_rating_all, train_indices_all, test_indices_all = gen_train_test(user_train_rating)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "train_user_all = np.nonzero(np.count_nonzero(train_rating_all, axis=1))[0]\n",
    "\n",
    "autoencoder = AutoEncoder(user_num=total_usr, item_num=total_item, mode='user', denoise_function='dropout', \n",
    "                          loss_function='cross_entropy', batch_size=1, epochs=200)\n",
    "\n",
    "\n",
    "autoencoder.train(rating=train_rating_all,\n",
    "                  train_idents=train_user_all,\n",
    "                  train_indices=train_indices_all,\n",
    "                  test_indices=test_indices_all,\n",
    "                  topN=None,\n",
    "                  weight=None)\n",
    "\n",
    "autoencoder.model_save(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x123187dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loss = autoencoder.log['train_loss']\n",
    "\n",
    "plt.plot(range(len(train_loss)), train_loss, color='blue', label='Train loss')\n",
    "# plt.plot(range(len(test_loss)), test_loss, color='red', label='Test loss')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.xlabel('#Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AP@5:  0.13949376006441236\n",
      "AP@10:  0.11334636115584189\n"
     ]
    }
   ],
   "source": [
    "test_ap_5 = autoencoder.log['ap@5']\n",
    "test_ap_10 = autoencoder.log['ap@10']\n",
    "\n",
    "\"\"\"plt.plot(range(5, (len(test_ap)+1)*5, 5), test_ap, color='green', label='Test AP')\n",
    "# plt.plot(range(len(test_loss)), test_loss, color='red', label='Test loss')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.title(\"Train 200 epoch\")\n",
    "plt.xlabel('#Epoch')\n",
    "plt.ylabel('AP')\n",
    "plt.show()\"\"\"\n",
    "\n",
    "# print (np.mean(top_N_ap))\n",
    "\n",
    "print (\"AP@5: \", max(test_ap_5))\n",
    "print (\"AP@10: \", max(test_ap_10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@5:  0.18810386473429963\n",
      "Recall@10:  0.1833836553945252\n"
     ]
    }
   ],
   "source": [
    "test_recall_5 = autoencoder.log['recall@5']\n",
    "test_recall_10 = autoencoder.log['recall@10']\n",
    "\n",
    "\"\"\"plt.plot(range(5, (len(test_recall)+1)*5, 5), test_recall, color='green', label='Test Recall')\n",
    "# plt.plot(range(len(test_loss)), test_loss, color='red', label='Test loss')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.title(\"Train 200 epoch\")\n",
    "plt.xlabel('#Epoch')\n",
    "plt.ylabel('Recall')\n",
    "plt.show()\"\"\"\n",
    "\n",
    "# print (np.mean(top_N_ap))\n",
    "\n",
    "print (\"Recall@5: \", max(test_recall_5))\n",
    "print (\"Recall@10: \", max(test_recall_10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "autoencoder = AutoEncoder(user_num=total_usr, item_num=total_item, mode='user', loss_function='cross_entropy',\n",
    "                          batch_size=100, epochs=1000)\n",
    "autoencoder.model_load(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_onehot_vectors = autoencoder.sess.run(autoencoder.vector_matrix)\n",
    "u_vectors = np.load('../data/itri/user_vectors.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_vectors = np.zeros((total_usr, 20), dtype=np.float32)\n",
    "for i in range(total_usr):\n",
    "    feature_vectors[i] = autoencoder.sess.run(\n",
    "        autoencoder.code,\n",
    "        feed_dict={\n",
    "            autoencoder.input: [train_rating_all[i]],\n",
    "            autoencoder.ident: [i]\n",
    "        })\n",
    "    \n",
    "np.save('../data/itri/feature_vectors.npy', feature_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "user_onehot_vectors = autoencoder.sess.run(autoencoder.vector_matrix)\n",
    "\n",
    "np.save('../data/itri/user_vectors.npy', user_onehot_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
