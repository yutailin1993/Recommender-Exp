{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from preprocess import Preprocess\n",
    "from ProbabilisticMatrixFactorization import PMF\n",
    "import tensorflow as tf\n",
    "import rrn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('rating_data.csv')\n",
    "df['freq'] = df.groupby('uid')['uid'].transform('count')  # count frequncy by column's values\n",
    "df = df[df['freq'] > 5]  # remove row which corresponding frequence < 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top List preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_item = pd.DataFrame(df['iid'])\n",
    "df_item.column = ['iid']\n",
    "df_item['freq'] = df_item.groupby('iid')['iid'].transform('count')\n",
    "df_item = df_item.drop_duplicates()\n",
    "df_item = df_item.sort_values(by=['freq'], ascending=False)\n",
    "top_list = df_item['iid'].as_matrix()\n",
    "\n",
    "top_ranks = []\n",
    "for i in range(1, 10):\n",
    "    top_ranks.append(top_list[:i*10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def get_map(list_):\n",
    "    map_ = {}\n",
    "    for idx, ident in enumerate(list_):\n",
    "        map_[ident] = idx\n",
    "        \n",
    "    return map_\n",
    "\n",
    "def train_test_split(df, time_interval, split_rate= 0.125):\n",
    "    start_time = min(df['timestamp'])\n",
    "    end_time = max(df['timestamp'])\n",
    "    time_elapse = (end_time-start_time) // time_interval\n",
    "    split_time = start_time + math.floor(time_elapse * (1-split_rate)) * time_interval\n",
    "    \n",
    "    df_train = df[df['timestamp'] < split_time]\n",
    "    df_test = df[df['timestamp'] >= split_time]\n",
    "    \n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "userList = np.unique(df['uid'])\n",
    "itemList = np.unique(df['iid'])\n",
    "user_map = get_map(userList)\n",
    "item_map = get_map(itemList)\n",
    "initial_time = min(df['timestamp'])\n",
    "\n",
    "df_train, df_test = train_test_split(df, 3 * 30 * 24 * 3600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOG_LOSS with AdaGrad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "user_hparas = get_hparas('USER')\n",
    "item_hparas = get_hparas('ITEM')\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "model = rrn.RRN(user_hparas=user_hparas, item_hparas=item_hparas, lr=0.01, epochs=200, loss_function='log_loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "model.train(df, user_vectors, item_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "train_loss = model.log['train_loss']\n",
    "\n",
    "plt.plot(range(len(train_loss)), train_loss, color='blue', label='Train loss')\n",
    "# plt.plot(range(len(test_loss)), test_loss, color='red', label='Test loss')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.xlabel('#Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMSE with Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_vectors = np.load('user_vectors.npy')\n",
    "item_vectors = np.load('item_vectors.npy')\n",
    "\n",
    "item_train_list = np.unique(df_train['iid'])\n",
    "item_test_list = np.unique(df_test['iid'])\n",
    "\n",
    "user_train_hparas = {\n",
    "            'NAME': 'USER',\n",
    "            'EMBED_UNITS': 40,\n",
    "            'BATCH_SIZE': 64,\n",
    "            'LSTM_UNITS': 40,\n",
    "            'LATENT_UNITS': 20,\n",
    "            'ITEM_NUM': len(itemList)+3,\n",
    "            'TRAIN_TIME_ELAPSE': 21,\n",
    "            'TEST_TIME_ELAPSE': 3,\n",
    "            'STATIONARY_LENGTH': 20,\n",
    "        }\n",
    "\n",
    "item_train_hparas = {\n",
    "            'NAME': 'ITEM',\n",
    "            'EMBED_UNITS': 40,\n",
    "            'BATCH_SIZE': len(item_train_list),\n",
    "            'LATENT_UNITS': 20,\n",
    "            'LSTM_UNITS': 40,\n",
    "            'TRAIN_TIME_ELAPSE': 21,\n",
    "            'TEST_TIME_ELAPSE': 3,\n",
    "            'USER_NUM': len(userList)+3,\n",
    "            'STATIONARY_LENGTH': 20\n",
    "        }\n",
    "\n",
    "user_test_hparas = {\n",
    "            'NAME': 'USER',\n",
    "            'EMBED_UNITS': 40,\n",
    "            'BATCH_SIZE': 64,\n",
    "            'LSTM_UNITS': 40,\n",
    "            'LATENT_UNITS': 20,\n",
    "            'ITEM_NUM': len(itemList)+3,\n",
    "            'TRAIN_TIME_ELAPSE': 21,\n",
    "            'TEST_TIME_ELAPSE': 3,\n",
    "            'STATIONARY_LENGTH': 20,\n",
    "        }\n",
    "\n",
    "item_test_hparas = {\n",
    "            'NAME': 'ITEM',\n",
    "            'EMBED_UNITS': 40,\n",
    "            'BATCH_SIZE': len(item_test_list),\n",
    "            'LATENT_UNITS': 20,\n",
    "            'LSTM_UNITS': 40,\n",
    "            'TRAIN_TIME_ELAPSE': 21,\n",
    "            'TEST_TIME_ELAPSE': 3,\n",
    "            'USER_NUM': len(userList)+3,\n",
    "            'STATIONARY_LENGTH': 20\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "model = rrn.RRN(user_hparas=user_train_hparas, item_hparas=item_train_hparas, \n",
    "                user_vectors=user_vectors, item_vectors=item_vectors,\n",
    "                is_train=True, lr=0.01, epochs=200, loss_function='log_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.train(df_train, user_map, item_map, initial_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "train_loss = model.log['train_loss']\n",
    "\n",
    "plt.plot(range(len(train_loss)), train_loss, color='blue', label='Train loss')\n",
    "# plt.plot(range(len(test_loss)), test_loss, color='red', label='Test loss')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.xlabel('#Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.model_save(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "model = rrn.RRN(user_hparas=user_test_hparas, item_hparas=item_test_hparas, \n",
    "                user_vectors=user_vectors, item_vectors=item_vectors,\n",
    "                is_train=False, loss_function='log_loss')\n",
    "\n",
    "model.model_load(1)\n",
    "losses = model.test(df_test, user_map, item_map, initial_time, individually=False)\n",
    "print (sum(losses)/len(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "model = rrn.RRN(user_hparas=user_test_hparas, item_hparas=item_test_hparas, \n",
    "                user_vectors=user_vectors, item_vectors=item_vectors,\n",
    "                is_train=False, loss_function='rmse')\n",
    "\n",
    "model.model_load(1)\n",
    "\n",
    "for i in top_ranks:\n",
    "    losses = model.test(df_test, user_map, item_map, initial_time, individually=True, top_rank=i)\n",
    "    print (\"top%d %s loss: %f\" % (len(i), model.loss_function, sum(losses)/len(losses)))\n",
    "    \n",
    "print ()\n",
    "losses = model.test(df_test, user_map, item_map, initial_time, individually=False, top_rank=None)\n",
    "print (\"All items %s loss: %f\" % (model.loss_function, sum(losses)/len(losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep = Preprocess(df_test, user_map, item_map, initial_time, 'zero_one')\n",
    "\n",
    "user_input, item_input, ground_truth, batch_user, batch_item = prep.gen_batch(0)\n",
    "u_static_vector = prep.get_latent_vector(batch_user, user_vectors, 'user')\n",
    "i_static_vector = prep.get_latent_vector(batch_item, item_vectors, 'item')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.sess.run(\n",
    "    model.logits,\n",
    "    feed_dict={\n",
    "        model.user_input: user_input,\n",
    "        model.item_input: item_input,\n",
    "        model.ground_truth: ground_truth,\n",
    "        model.user_stationary_factor: u_static_vector,\n",
    "        model.item_stationary_factor: i_static_vector,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print (output[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
