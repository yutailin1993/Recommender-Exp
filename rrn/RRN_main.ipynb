{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/larry/Py3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from preprocess import Preprocess\n",
    "import tensorflow as tf\n",
    "import rrn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data and user/item vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/class/rating_data.csv')\n",
    "df['freq'] = df.groupby('uid')['uid'].transform('count')  # count frequncy by column's values\n",
    "df = df[df['freq'] > 5]  # remove row which corresponding frequence < 5\n",
    "\n",
    "user_vectors = np.load('../data/class/user_vectors.npy')\n",
    "item_vectors = np.load('../data/class/item_vectors.npy')\n",
    "\n",
    "user_time_interval = 3 * 30\n",
    "item_time_interval = 3 * 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top List preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_item = pd.DataFrame(df['iid'])\n",
    "df_item.column = ['iid']\n",
    "df_item['freq'] = df_item.groupby('iid')['iid'].transform('count')\n",
    "df_item = df_item.drop_duplicates()\n",
    "df_item = df_item.sort_values(by=['freq'], ascending=False)\n",
    "top_list = df_item['iid'].as_matrix()\n",
    "\n",
    "top_ranks = []\n",
    "for i in range(1, 10):\n",
    "    top_ranks.append(top_list[:i*10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def get_map(list_):\n",
    "    map_ = {}\n",
    "    for idx, ident in enumerate(list_):\n",
    "        map_[ident] = idx\n",
    "        \n",
    "    return map_\n",
    "\n",
    "def train_test_split(df, time_interval, split_rate= 0.125):\n",
    "    start_time = min(df['timestamp'])\n",
    "    end_time = max(df['timestamp'])\n",
    "    time_elapse = (end_time-start_time) // time_interval\n",
    "    split_time = start_time + math.floor(time_elapse * (1-split_rate)) * time_interval\n",
    "    \n",
    "    df_train = df[df['timestamp'] < split_time]\n",
    "    df_test = df[df['timestamp'] >= split_time]\n",
    "    \n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "userList = np.unique(df['uid'])\n",
    "itemList = np.unique(df['iid'])\n",
    "user_map = get_map(userList)\n",
    "item_map = get_map(itemList)\n",
    "initial_time = min(df['timestamp'])\n",
    "\n",
    "df_train, df_test = train_test_split(df, user_time_interval * 24 * 3600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_hparas(batch_size, vector_length, time_interval, name):\n",
    "    hparas={\n",
    "        'NAME': name,\n",
    "        'EMBED_UNITS': 40,\n",
    "        'BATCH_SIZE': batch_size,\n",
    "        'LSTM_UNITS': 40,\n",
    "        'LATENT_UNITS': 20,\n",
    "        'VECTOR_LENGTH': vector_length+3,\n",
    "        'TRAIN_TIME_ELAPSE': 21,\n",
    "        'TEST_TIME_ELAPSE': 3,\n",
    "        'STATIONARY_LENGTH': 20,\n",
    "        'TIME_INTERVAL': time_interval,\n",
    "    }\n",
    "    \n",
    "    return hparas\n",
    "\n",
    "item_train_list = np.unique(df_train['iid'])\n",
    "item_test_list = np.unique(df_test['iid'])\n",
    "\n",
    "user_train_hparas = get_hparas(64, len(itemList), user_time_interval, 'USER')\n",
    "item_train_hparas = get_hparas(len(item_train_list), len(userList), item_time_interval, 'ITEM')\n",
    "user_test_hparas = get_hparas(64, len(itemList), user_time_interval, 'USER')\n",
    "item_test_hparas = get_hparas(len(item_test_list), len(userList), item_time_interval, 'ITEM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "model = rrn.RRN(user_hparas=user_train_hparas, item_hparas=item_train_hparas, \n",
    "                user_vectors=user_vectors, item_vectors=item_vectors,\n",
    "                is_train=True, lr=0.01, epochs=200, loss_function='log_loss')\n",
    "\n",
    "model.train(df_train, user_map, item_map, initial_time)\n",
    "model.model_save('itri_log_loss')\n",
    "\n",
    "train_loss = model.log['train_loss']\n",
    "plt.plot(range(len(train_loss)), train_loss, color='blue', label='Train loss')\n",
    "# plt.plot(range(len(test_loss)), test_loss, color='red', label='Test loss')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.xlabel('#Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model/rrn_class_rmse.ckpt\n",
      "top10 rmse loss: 0.049372\n",
      "top20 rmse loss: 0.097232\n",
      "top30 rmse loss: 0.129399\n",
      "top40 rmse loss: 0.168768\n",
      "top50 rmse loss: 0.205361\n",
      "top60 rmse loss: 0.237629\n",
      "top70 rmse loss: 0.267704\n",
      "top80 rmse loss: 0.293143\n",
      "top90 rmse loss: 0.318163\n",
      "\n",
      "All items rmse loss: 0.608419\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "model = rrn.RRN(user_hparas=user_test_hparas, item_hparas=item_test_hparas, \n",
    "                user_vectors=user_vectors, item_vectors=item_vectors,\n",
    "                is_train=False, loss_function='rmse')\n",
    "\n",
    "model.model_load('class_rmse')\n",
    "\n",
    "for i in top_ranks:\n",
    "    losses = model.test(df_test, user_map, item_map, initial_time, individually=True, top_rank=i)\n",
    "    print (\"top%d %s loss: %f\" % (len(i), model.loss_function, sum(losses)/len(losses)))\n",
    "    \n",
    "print ()\n",
    "losses = model.test(df_test, user_map, item_map, initial_time, individually=False, top_rank=None)\n",
    "print (\"All items %s loss: %f\" % (model.loss_function, sum(losses)/len(losses)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find bug Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prep = Preprocess(df_test, user_map, item_map, initial_time, 'zero_one')\n",
    "\n",
    "user_input, item_input, ground_truth, batch_user, batch_item = prep.gen_batch(0)\n",
    "u_static_vector = prep.get_latent_vector(batch_user, user_vectors, 'user')\n",
    "i_static_vector = prep.get_latent_vector(batch_item, item_vectors, 'item')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = model.sess.run(\n",
    "    model.logits,\n",
    "    feed_dict={\n",
    "        model.user_input: user_input,\n",
    "        model.item_input: item_input,\n",
    "        model.ground_truth: ground_truth,\n",
    "        model.user_stationary_factor: u_static_vector,\n",
    "        model.item_stationary_factor: i_static_vector,\n",
    "    })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print (output[0][0][:10])\n",
    "print (ground_truth[1][0][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
